// lib/hunterMedia.ts - Complete version with all missing types and methods
import ExifReader from 'exifreader'
import { Pool } from 'pg'
import { promises as fs } from 'fs'
import path from 'path'
import { scanAndProcessNewFiles as enhancedScanAndProcessNewFiles } from './enhancedMediaScanner'

// EXIF Data Types - matching ExifReader's actual output format
export interface ExifData {
  DateTime?: {
    description: string
    value?: any
  }
  DateTimeOriginal?: {
    description: string
    value?: any
  }
  DateTimeDigitized?: {
    description: string
    value?: any
  }
  GPSLatitude?: {
    description: string
    value?: any
  }
  GPSLongitude?: {
    description: string
    value?: any
  }
  GPSLatitudeRef?: {
    description: string
    value?: any
  }
  GPSLongitudeRef?: {
    description: string
    value?: any
  }
  Make?: {
    description: string
    value?: any
  }
  Model?: {
    description: string
    value?: any
  }
  Orientation?: {
    description: string
    value?: any
  }
  XResolution?: {
    description: string
    value?: any
  }
  YResolution?: {
    description: string
    value?: any
  }
  [key: string]: any
}

// Tag Types
export type TagType = 'person' | 'dog' | 'activity' | 'location' | 'mood' | 'event' | 'object'

// Type guard function
export function isValidTagType(type: string): type is TagType {
  return ['person', 'dog', 'activity', 'location', 'mood', 'event', 'object'].includes(type)
}

// Core Media Types
export interface MediaFile {
  id: number
  filename: string
  original_filename?: string
  file_path: string
  media_type: 'image' | 'video'
  file_size?: number
  taken_at?: string
  uploaded_at?: string // This is what the database actually has
  location_lat?: number
  location_lng?: number
  location_name?: string
  description?: string
  camera_make?: string // Separate fields in database
  camera_model?: string // Separate fields in database
  uploaded_by?: string
  upload_session_id?: number
  orientation?: number

  // Computed properties for backwards compatibility
  created_at?: string // Will map to uploaded_at
  camera?: string // Will combine camera_make + camera_model

  // Thumbnail paths (generated by the system)
  thumbnail_150?: string
  thumbnail_500?: string
  thumbnail_1200?: string

  // Tags relationship
  tags?: Array<{
    id: number
    tag_type: string
    tag_value: string
    value: string // For backward compatibility
    type: string // For compatibility with frontend
    added_by?: string
    added_at?: string
  }>

  // Computed properties
  has_location?: boolean
}

export interface MediaTag {
  id: number
  media_id: number
  tag_type: string
  tag_value: string
  added_by?: string
  added_at?: string
}

export interface SearchFilters {
  search?: string
  startDate?: string
  endDate?: string
  location?: string
  tags?: string[]
  type?: 'image' | 'video'
  limit?: number | string
  offset?: number
  year?: number
  // Additional filters for new API routes
  mediaType?: 'image' | 'video'
  dateFrom?: Date
  dateTo?: Date
  hasLocation?: boolean
}

export interface MediaResponse {
  media: MediaFile[]
  total: number
  hasMore: boolean
  filters: SearchFilters
}

// EXIF Processing Types
export interface ProcessedExifData {
  dateTime?: Date
  latitude?: number
  longitude?: number
  camera?: string
  orientation?: number
}

// Tag suggestion response type
export interface TagSuggestion {
  type: string
  value: string
  count: number
}

// Database connection
let pool: Pool | null = null

function getPool(): Pool {
  if (!pool) {
    const dbConfig = {
      host: process.env.POSTGRES_HOST || process.env.DB_HOST || 'postgres',
      port: parseInt(process.env.POSTGRES_PORT || process.env.DB_PORT || '5432'),
      database: process.env.POSTGRES_DB || process.env.DB_NAME || 'agents_platform',
      user: process.env.POSTGRES_USER || process.env.DB_USER || 'hunter_admin',
      password: process.env.POSTGRES_PASSWORD || process.env.DB_PASSWORD,
      ssl: false  // Disable SSL for local Docker PostgreSQL
    }

    console.log('üîß Database connection config:', {
      host: dbConfig.host,
      port: dbConfig.port,
      database: dbConfig.database,
      user: dbConfig.user,
      hasPassword: !!dbConfig.password,
      ssl: dbConfig.ssl
    })

    pool = new Pool(dbConfig)
  }
  return pool
}

// Utility Functions
export function extractExifData(buffer: ArrayBuffer): ProcessedExifData {
  try {
    // ExifReader expects ArrayBuffer or Uint8Array
    const tags = ExifReader.load(buffer) as any
    const result: ProcessedExifData = {}

    // Extract date/time
    const dateTimeOriginal = tags.DateTimeOriginal || tags.DateTime || tags.DateTimeDigitized
    if (dateTimeOriginal && dateTimeOriginal.description) {
      try {
        // EXIF date format: "YYYY:MM:DD HH:mm:ss"
        const dateStr = dateTimeOriginal.description.replace(/^(\d{4}):(\d{2}):(\d{2})/, '$1-$2-$3')
        result.dateTime = new Date(dateStr)
      } catch (e) {
        console.warn('Could not parse EXIF date:', dateTimeOriginal.description)
      }
    }

    // Extract GPS coordinates
    if (tags.GPSLatitude && tags.GPSLongitude) {
      try {
        let lat: number | undefined
        let lng: number | undefined

        // Handle different formats from ExifReader
        if (typeof tags.GPSLatitude.value === 'number') {
          lat = tags.GPSLatitude.value
        } else if (typeof tags.GPSLatitude.description === 'string') {
          lat = parseFloat(tags.GPSLatitude.description)
        }

        if (typeof tags.GPSLongitude.value === 'number') {
          lng = tags.GPSLongitude.value
        } else if (typeof tags.GPSLongitude.description === 'string') {
          lng = parseFloat(tags.GPSLongitude.description)
        }

        // Apply hemisphere corrections
        if (lat && lng) {
          if (tags.GPSLatitudeRef?.description === 'S') lat = -lat
          if (tags.GPSLongitudeRef?.description === 'W') lng = -lng

          result.latitude = lat
          result.longitude = lng
        }
      } catch (e) {
        console.warn('Could not parse GPS coordinates:', e)
      }
    }

    // Extract camera info
    if (tags.Make || tags.Model) {
      const make = tags.Make?.description || ''
      const model = tags.Model?.description || ''
      result.camera = `${make} ${model}`.trim()
    }

    // Extract orientation
    if (tags.Orientation?.value) {
      result.orientation = tags.Orientation.value
    }

    return result
  } catch (error) {
    console.warn('Error reading EXIF data:', error)
    return {}
  }
}

/**
 * Parse date from filename patterns like:
 * - 20211220_092719.mp4 -> 2021-12-20 09:27:19
 * - IMG_20211220_092719.jpg -> 2021-12-20 09:27:19
 * - VID_20211220_092719.mp4 -> 2021-12-20 09:27:19
 */
export function parseDateFromFilename(filename: string): Date | null {
  console.log(`üìÖ Attempting to parse date from filename: ${filename}`)

  // Pattern 1: YYYYMMDD_HHMMSS (your video format)
  const pattern1 = /(\d{8})_(\d{6})/
  const match1 = filename.match(pattern1)

  if (match1) {
    const [, dateStr, timeStr] = match1
    const year = parseInt(dateStr.substring(0, 4))
    const month = parseInt(dateStr.substring(4, 6)) - 1 // JavaScript months are 0-based
    const day = parseInt(dateStr.substring(6, 8))
    const hour = parseInt(timeStr.substring(0, 2))
    const minute = parseInt(timeStr.substring(2, 4))
    const second = parseInt(timeStr.substring(4, 6))

    const date = new Date(year, month, day, hour, minute, second)
    if (!isNaN(date.getTime())) {
      console.log(`‚úÖ Successfully parsed date: ${date.toISOString()}`)
      return date
    }
  }

  // Pattern 2: IMG_YYYYMMDD_HHMMSS or VID_YYYYMMDD_HHMMSS
  const pattern2 = /(?:IMG_|VID_)?(\d{8})_(\d{6})/
  const match2 = filename.match(pattern2)

  if (match2) {
    const [, dateStr, timeStr] = match2
    const year = parseInt(dateStr.substring(0, 4))
    const month = parseInt(dateStr.substring(4, 6)) - 1
    const day = parseInt(dateStr.substring(6, 8))
    const hour = parseInt(timeStr.substring(0, 2))
    const minute = parseInt(timeStr.substring(2, 4))
    const second = parseInt(timeStr.substring(4, 6))

    const date = new Date(year, month, day, hour, minute, second)
    if (!isNaN(date.getTime())) {
      console.log(`‚úÖ Successfully parsed date: ${date.toISOString()}`)
      return date
    }
  }

  // Pattern 3: YYYY-MM-DD format
  const pattern3 = /(\d{4})-(\d{2})-(\d{2})/
  const match3 = filename.match(pattern3)

  if (match3) {
    const [, year, month, day] = match3
    const date = new Date(parseInt(year), parseInt(month) - 1, parseInt(day))
    if (!isNaN(date.getTime())) {
      console.log(`‚úÖ Successfully parsed date (date only): ${date.toISOString()}`)
      return date
    }
  }

  console.log(`‚ö†Ô∏è Could not parse date from filename: ${filename}`)
  return null
}

/**
 * Permanently delete a media file and all associated data
 * This is irreversible - use with extreme caution
 */
export async function deleteMediaFile(id: number): Promise<{
  success: boolean
  deletedFiles: string[]
  errors: string[]
}> {
  const pool = getPool()
  const deletedFiles: string[] = []
  const errors: string[] = []

  try {
    // 1. Get media file details before deletion
    const media = await getMediaById(id)
    if (!media) {
      throw new Error(`Media file with ID ${id} not found`)
    }

    console.log(`üóëÔ∏è Starting deletion process for media ID ${id}: ${media.filename}`)

    // 2. Delete associated tags first (foreign key constraint)
    try {
      const deleteTagsQuery = `DELETE FROM hunter_media.tags WHERE media_id = $1`
      const tagResult = await pool.query(deleteTagsQuery, [id])
      console.log(`üè∑Ô∏è Deleted ${tagResult.rowCount || 0} associated tags`)
    } catch (error) {
      errors.push(`Failed to delete tags: ${error instanceof Error ? error.message : 'Unknown error'}`)
    }

    // 3. Delete physical files
    const MEDIA_BASE_PATH = '/app/hunter-media'

    // Delete original file
    try {
      const originalPath = path.join(MEDIA_BASE_PATH, media.file_path)
      await fs.unlink(originalPath)
      deletedFiles.push(originalPath)
      console.log(`üìÅ Deleted original file: ${originalPath}`)
    } catch (error) {
      errors.push(`Failed to delete original file: ${error instanceof Error ? error.message : 'Unknown error'}`)
    }

    // Delete thumbnails if they exist
    const thumbnailSizes = ['150', '500', '1200']
    const ext = path.extname(media.filename)
    const baseName = path.basename(media.filename, ext)

    for (const size of thumbnailSizes) {
      if (media[`thumbnail_${size}` as keyof typeof media]) {
        try {
          const thumbnailPath = path.join(MEDIA_BASE_PATH, 'thumbnails', size, `${baseName}_${size}${ext}`)
          await fs.unlink(thumbnailPath)
          deletedFiles.push(thumbnailPath)
          console.log(`üñºÔ∏è Deleted ${size}px thumbnail: ${thumbnailPath}`)
        } catch (error) {
          errors.push(`Failed to delete ${size}px thumbnail: ${error instanceof Error ? error.message : 'Unknown error'}`)
        }
      }
    }

    // 4. Delete database record
    try {
      const deleteMediaQuery = `DELETE FROM hunter_media.media WHERE id = $1`
      const mediaResult = await pool.query(deleteMediaQuery, [id])
      if (mediaResult.rowCount === 0) {
        throw new Error('No media record was deleted')
      }
      console.log(`üíæ Deleted database record for media ID ${id}`)
    } catch (error) {
      errors.push(`Failed to delete database record: ${error instanceof Error ? error.message : 'Unknown error'}`)
    }

    const success = errors.length === 0
    console.log(`${success ? '‚úÖ' : '‚ö†Ô∏è'} Deletion ${success ? 'completed successfully' : 'completed with errors'} for ${media.filename}`)

    return {
      success,
      deletedFiles,
      errors
    }

  } catch (error) {
    console.error('‚ùå Critical error during deletion:', error)
    return {
      success: false,
      deletedFiles,
      errors: [...errors, `Critical error: ${error instanceof Error ? error.message : 'Unknown error'}`]
    }
  }
}

// Authentication function
export async function verifyFamilyAuth(username: string, password: string): Promise<boolean> {
  // Simple hardcoded auth for now - enhance with database later
  const validCredentials = [
    { username: 'boyboy', password: '010918' },
    { username: 'hunter', password: 'memorial' }
  ]

  return validCredentials.some(cred =>
    cred.username === username && cred.password === password
  )
}

// File system utilities
export function isImageFile(filename: string): boolean {
  const imageExtensions = ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp', '.heic', '.heif']
  return imageExtensions.includes(path.extname(filename).toLowerCase())
}

export function isVideoFile(filename: string): boolean {
  const videoExtensions = ['.mp4', '.mov', '.avi', '.mkv', '.webm', '.m4v']
  return videoExtensions.includes(path.extname(filename).toLowerCase())
}

export function isValidCacheTimestamp(timestamp: number): boolean {
  const expirationTime = 24 * 60 * 60 * 1000
  return (Date.now() - timestamp) < expirationTime
}

// Database operations
export async function saveMediaFile(
  filename: string,
  filePath: string,
  mediaType: 'image' | 'video',
  fileSize: number,
  exifData: ProcessedExifData
): Promise<MediaFile> {
  const pool = getPool()

  const query = `
    INSERT INTO hunter_media.media 
    (filename, original_filename, file_path, media_type, file_size, taken_at, location_lat, location_lng, camera_make, camera_model, uploaded_by, orientation)
    VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12)
    RETURNING *
  `

  // Extract camera make and model from combined camera string
  const cameraParts = exifData.camera ? exifData.camera.split(' ') : []
  const cameraMake = cameraParts[0] || null
  const cameraModel = cameraParts.slice(1).join(' ') || null

  const properFilePath = filePath.startsWith('/originals/') ? filePath : `/originals/${filePath}`

  const values: (string | number | Date | null)[] = [
    filename,
    filename, // original_filename same as filename for now
    filePath,
    mediaType,
    fileSize,
    exifData.dateTime || null,
    exifData.latitude || null,
    exifData.longitude || null,
    cameraMake,
    cameraModel,
    'system', // uploaded_by
    exifData.orientation || 1 // orientation, default to 1 (normal)
  ]

  const result = await pool.query(query, values)
  const row = result.rows[0]

  // Add computed fields for compatibility
  return {
    ...row,
    created_at: row.uploaded_at,
    camera: [row.camera_make, row.camera_model].filter(Boolean).join(' ') || undefined,
    has_location: !!(row.location_lat && row.location_lng)
  }
}

export async function getMediaFiles(filters: SearchFilters = {}): Promise<MediaResponse> {
  const pool = getPool()

  let query = `
    SELECT m.*, 
           array_agg(
             CASE WHEN t.id IS NOT NULL 
             THEN json_build_object('id', t.id, 'tag_type', t.tag_type, 'tag_value', t.tag_value, 'value', t.tag_value, 'type', t.tag_type)
             ELSE NULL END
           ) FILTER (WHERE t.id IS NOT NULL) as tags
    FROM hunter_media.media m
    LEFT JOIN hunter_media.tags t ON m.id = t.media_id
  `

  const conditions: string[] = []
  const values: any[] = []
  let valueIndex = 1

  // Apply filters
  if (filters.search) {
    conditions.push(`(m.filename ILIKE $${valueIndex} OR m.description ILIKE $${valueIndex} OR m.location_name ILIKE $${valueIndex})`)
    values.push(`%${filters.search}%`)
    valueIndex++
  }

  if (filters.type || filters.mediaType) {
    conditions.push(`m.media_type = $${valueIndex}`)
    values.push(filters.type || filters.mediaType)
    valueIndex++
  }

  if (filters.startDate || filters.dateFrom) {
    conditions.push(`m.taken_at >= $${valueIndex}`)
    values.push(filters.startDate || filters.dateFrom)
    valueIndex++
  }

  if (filters.endDate || filters.dateTo) {
    conditions.push(`m.taken_at <= $${valueIndex}`)
    values.push(filters.endDate || filters.dateTo)
    valueIndex++
  }

  if (filters.year) {
    conditions.push(`EXTRACT(YEAR FROM m.taken_at) = $${valueIndex}`)
    values.push(filters.year)
    valueIndex++
  }

  if (filters.hasLocation) {
    conditions.push(`m.location_lat IS NOT NULL AND m.location_lng IS NOT NULL`)
  }

  if (filters.tags && filters.tags.length > 0) {
    // AND logic: media must have ALL specified tags
    conditions.push(`
      m.id IN (
        SELECT media_id 
        FROM hunter_media.tags 
        WHERE tag_value = ANY($${valueIndex})
        GROUP BY media_id 
        HAVING COUNT(DISTINCT tag_value) = ${filters.tags.length}
      )
    `)
    values.push(filters.tags)
    valueIndex++
  }

  if (conditions.length > 0) {
    query += ' WHERE ' + conditions.join(' AND ')
  }

  query += ` GROUP BY m.id ORDER BY m.taken_at DESC, m.uploaded_at DESC`

  // Add pagination
  const limit = parseInt(String(filters.limit || 50))
  const offset = parseInt(String(filters.offset || 0))

  query += ` LIMIT $${valueIndex} OFFSET $${valueIndex + 1}`
  values.push(limit, offset)

  // Add this debugging before the query execution:
  console.log('Generated SQL query:', query)
  console.log('Query values:', values)
  console.log('Value types:', values.map(v => typeof v))

  const result = await pool.query(query, values)

  // Get total count
  let countQuery = `SELECT COUNT(DISTINCT m.id) as total FROM hunter_media.media m`
  const countValues: any[] = []
  let countValueIndex = 1

  if (filters.tags && filters.tags.length > 0) {
    countQuery += ` LEFT JOIN hunter_media.tags t ON m.id = t.media_id`
  }

  if (conditions.length > 0) {
    // Rebuild conditions for count query without LIMIT/OFFSET
    const countConditions: string[] = []

    if (filters.search) {
      countConditions.push(`(m.filename ILIKE $${countValueIndex} OR m.description ILIKE $${countValueIndex} OR m.location_name ILIKE $${countValueIndex})`)
      countValues.push(`%${filters.search}%`)
      countValueIndex++
    }

    if (filters.type || filters.mediaType) {
      countConditions.push(`m.media_type = $${countValueIndex}`)
      countValues.push(filters.type || filters.mediaType)
      countValueIndex++
    }

    if (filters.startDate || filters.dateFrom) {
      countConditions.push(`m.taken_at >= $${countValueIndex}`)
      countValues.push(filters.startDate || filters.dateFrom)
      countValueIndex++
    }

    if (filters.endDate || filters.dateTo) {
      countConditions.push(`m.taken_at <= $${countValueIndex}`)
      countValues.push(filters.endDate || filters.dateTo)
      countValueIndex++
    }

    if (filters.year) {
      countConditions.push(`EXTRACT(YEAR FROM m.taken_at) = $${countValueIndex}`)
      countValues.push(filters.year)
      countValueIndex++
    }

    if (filters.hasLocation) {
      countConditions.push(`m.location_lat IS NOT NULL AND m.location_lng IS NOT NULL`)
    }

    if (filters.tags && filters.tags.length > 0) {
      // AND logic: media must have ALL specified tags
      countConditions.push(`
        m.id IN (
          SELECT media_id 
          FROM hunter_media.tags 
          WHERE tag_value = ANY($${countValueIndex})
          GROUP BY media_id 
          HAVING COUNT(DISTINCT tag_value) = ${filters.tags.length}
        )
      `)
      countValues.push(filters.tags)
      countValueIndex++
    }

    countQuery += ' WHERE ' + countConditions.join(' AND ')
  }

  const countResult = await pool.query(countQuery, countValues)
  const total = parseInt(countResult.rows[0].total)

  return {
    media: result.rows.map(row => ({
      ...row,
      created_at: row.uploaded_at, // Map for compatibility
      camera: [row.camera_make, row.camera_model].filter(Boolean).join(' ') || undefined,
      has_location: !!(row.location_lat && row.location_lng),
      // Ensure tags have correct structure
      tags: row.tags?.map((tag: any) => ({
        ...tag,
        value: tag.tag_value, // Backwards compatibility
        type: tag.tag_type    // Backwards compatibility
      }))
    })),
    total,
    hasMore: offset + limit < total,
    filters
  }
}

export async function getMediaById(id: number): Promise<MediaFile | null> {
  const pool = getPool()

  const query = `
    SELECT m.*, 
           array_agg(
             CASE WHEN t.id IS NOT NULL 
             THEN json_build_object('id', t.id, 'tag_type', t.tag_type, 'tag_value', t.tag_value, 'value', t.tag_value, 'type', t.tag_type)
             ELSE NULL END
           ) FILTER (WHERE t.id IS NOT NULL) as tags
    FROM hunter_media.media m
    LEFT JOIN hunter_media.tags t ON m.id = t.media_id
    WHERE m.id = $1
    GROUP BY m.id
  `

  const result = await pool.query(query, [id])
  if (result.rows.length === 0) return null

  const media = result.rows[0]
  return {
    ...media,
    created_at: media.uploaded_at, // Map for compatibility
    camera: [media.camera_make, media.camera_model].filter(Boolean).join(' ') || undefined,
    has_location: !!(media.location_lat && media.location_lng),
    // Ensure tags have correct structure
    tags: media.tags?.map((tag: any) => ({
      ...tag,
      value: tag.tag_value, // Backwards compatibility
      type: tag.tag_type    // Backwards compatibility
    }))
  }
}

export async function updateMediaFile(id: number, updates: Partial<MediaFile>): Promise<MediaFile | null> {
  const pool = getPool()

  const updateFields: string[] = []
  const values: (string | number | null)[] = []
  let valueIndex = 1

  const allowedFields = ['description', 'location_name', 'location_lat', 'location_lng']

  for (const [key, value] of Object.entries(updates)) {
    if (allowedFields.includes(key)) {
      updateFields.push(`${key} = $${valueIndex}`)
      values.push(value as string | number | null)
      valueIndex++
    }
  }

  if (updateFields.length === 0) return null

  const query = `
    UPDATE hunter_media.media
    SET ${updateFields.join(', ')}
    WHERE id = $${valueIndex}
    RETURNING *
  `
  values.push(id)

  const result = await pool.query(query, values)
  return result.rows[0] || null
}

// Fixed addMediaTag function for lib/hunterMedia.ts
// This should replace the existing addMediaTag function

export async function addMediaTag(mediaId: number, tagType: TagType | string, tagValue: string, addedBy: string = 'system'): Promise<MediaTag> {
  const pool = getPool()

  // Validate tag type if it's a string
  if (typeof tagType === 'string' && !isValidTagType(tagType)) {
    throw new Error(`Invalid tag type: ${tagType}`)
  }

  // First, try to insert the tag
  const insertQuery = `
    INSERT INTO hunter_media.tags (media_id, tag_type, tag_value, added_by)
    VALUES ($1, $2, $3, $4)
    ON CONFLICT (media_id, tag_type, tag_value) DO NOTHING
    RETURNING *
  `

  const insertResult = await pool.query(insertQuery, [mediaId, tagType, tagValue, addedBy])

  // If we got a result, the tag was successfully inserted
  if (insertResult.rows.length > 0) {
    return insertResult.rows[0]
  }

  // If no result, the tag already existed, so fetch the existing tag
  const selectQuery = `
    SELECT * FROM hunter_media.tags 
    WHERE media_id = $1 AND tag_type = $2 AND tag_value = $3
  `

  const selectResult = await pool.query(selectQuery, [mediaId, tagType, tagValue])

  if (selectResult.rows.length > 0) {
    return selectResult.rows[0]
  }

  // This should never happen, but just in case
  throw new Error(`Failed to add or find tag: ${tagType}=${tagValue} for media ${mediaId}`)
}

export async function removeMediaTag(tagId: number): Promise<boolean> {
  const pool = getPool()

  const query = `DELETE FROM hunter_media.tags WHERE id = $1`
  const result = await pool.query(query, [tagId])

  return (result.rowCount ?? 0) > 0
}

export async function removeMediaTagByValue(mediaId: number, tagType: string, tagValue: string): Promise<boolean> {
  const pool = getPool()

  const query = `DELETE FROM hunter_media.tags WHERE media_id = $1 AND tag_type = $2 AND tag_value = $3`
  const result = await pool.query(query, [mediaId, tagType, tagValue])

  return (result.rowCount ?? 0) > 0
}

export async function getTagSuggestions(tagType?: TagType | string): Promise<string[]> {
  const pool = getPool()

  let query = `
    SELECT tag_value, COUNT(*) as usage_count
    FROM hunter_media.tags
  `

  const values: string[] = []
  if (tagType) {
    query += ` WHERE tag_type = $1`
    values.push(tagType)
  }

  query += ` GROUP BY tag_value ORDER BY usage_count DESC, tag_value ASC`

  const result = await pool.query(query, values)
  return result.rows.map(row => row.tag_value)
}

export async function getExistingTags(tagType?: string): Promise<TagSuggestion[]> {
  const pool = getPool()

  let query = `
    SELECT tag_type as type, tag_value as value, COUNT(*) as count
    FROM hunter_media.tags
  `

  const values: string[] = []
  if (tagType) {
    query += ` WHERE tag_type = $1`
    values.push(tagType)
  }

  query += ` GROUP BY tag_type, tag_value ORDER BY count DESC, tag_value ASC`

  const result = await pool.query(query, values)
  return result.rows
}

export async function updateThumbnailPaths(id: number, thumbnails: {
  thumbnail_150?: string
  thumbnail_500?: string
  thumbnail_1200?: string
}): Promise<void> {
  const pool = getPool()

  const updateFields: string[] = []
  const values: (string | number)[] = []
  let valueIndex = 1

  for (const [key, value] of Object.entries(thumbnails)) {
    if (value) {
      updateFields.push(`${key} = $${valueIndex}`)
      values.push(value)
      valueIndex++
    }
  }

  if (updateFields.length === 0) return

  const query = `
    UPDATE hunter_media.media
    SET ${updateFields.join(', ')}
    WHERE id = $${valueIndex}
  `
  values.push(id)

  await pool.query(query, values)
}

// File scanning functions
export async function scanAndProcessNewFiles(adminUser: string): Promise<MediaFile[]> {
  const MEDIA_BASE_PATH = '/app/hunter-media/originals'
  const processedFiles: MediaFile[] = []

  try {
    const subdirs = await fs.readdir(MEDIA_BASE_PATH)

    for (const subdir of subdirs) {
      const subdirPath = path.join(MEDIA_BASE_PATH, subdir)
      const stat = await fs.stat(subdirPath)

      if (stat.isDirectory()) {
        const files = await fs.readdir(subdirPath)

        for (const filename of files) {
          const filePath = path.join(subdirPath, filename)
          const relativeFilePath = path.join(subdir, filename)

          if (isImageFile(filename) || isVideoFile(filename)) {
            // Check if already processed
            const existing = await getMediaByFilename(filename)
            if (existing) continue

            const fileStats = await fs.stat(filePath)
            const mediaType = isImageFile(filename) ? 'image' : 'video'

            let exifData: ProcessedExifData = {}

            if (isImageFile(filename)) {
              try {
                const buffer = await fs.readFile(filePath)
                // Ensure we get a proper ArrayBuffer, not SharedArrayBuffer
                const arrayBuffer = buffer.buffer instanceof ArrayBuffer
                  ? buffer.buffer.slice(buffer.byteOffset, buffer.byteOffset + buffer.byteLength)
                  : new ArrayBuffer(buffer.length)

                if (!(arrayBuffer instanceof ArrayBuffer)) {
                  // Fallback: copy buffer data to new ArrayBuffer
                  const newBuffer = new ArrayBuffer(buffer.length)
                  const view = new Uint8Array(newBuffer)
                  view.set(buffer)
                  exifData = extractExifData(newBuffer)
                } else {
                  exifData = extractExifData(arrayBuffer)
                }
              } catch (error) {
                console.warn(`Could not read EXIF for ${filename}:`, error)
              }
            }

            const savedFile = await saveMediaFile(
              filename,
              relativeFilePath,
              mediaType,
              fileStats.size,
              exifData
            )

            processedFiles.push(savedFile)
            console.log(`Processed: ${filename}`)
          }
        }
      }
    }
  } catch (error) {
    console.error('Error scanning files:', error)
    throw error
  }

  return processedFiles
}

async function getMediaByFilename(filename: string): Promise<MediaFile | null> {
  const pool = getPool()
  const query = `SELECT * FROM hunter_media.media WHERE filename = $1`
  const result = await pool.query(query, [filename])
  return result.rows[0] || null
}

// Database class wrapper for API routes
export class HunterMediaDB {
  static async scanAndProcessNewFiles(uploadedBy: string): Promise<any[]> {
    // Import dynamically to avoid circular dependencies
    return scanAndProcessNewFiles(uploadedBy)
  }

  // Alias for compatibility with API routes
  static async getMedia(filters: SearchFilters = {}): Promise<MediaResponse> {
    return getMediaFiles(filters)
  }

  static async getMediaById(id: number): Promise<MediaFile | null> {
    return getMediaById(id)
  }

  static async updateMediaFile(id: number, updates: Partial<MediaFile>): Promise<MediaFile | null> {
    return updateMediaFile(id, updates)
  }

  static async saveMediaFile(
    filename: string,
    filePath: string,
    mediaType: 'image' | 'video',
    fileSize: number,
    exifData: ProcessedExifData
  ): Promise<MediaFile> {
    return saveMediaFile(filename, filePath, mediaType, fileSize, exifData)
  }

  static async addMediaTag(mediaId: number, tagType: TagType | string, tagValue: string, addedBy: string = 'system'): Promise<MediaTag> {
    return addMediaTag(mediaId, tagType, tagValue, addedBy)
  }

  // New method for API compatibility
  static async addTag(mediaId: number, tagType: string, tagValue: string, adminUser: string): Promise<MediaTag> {
    return addMediaTag(mediaId, tagType, tagValue, adminUser)
  }

  static async removeMediaTag(tagId: number): Promise<boolean> {
    return removeMediaTag(tagId)
  }

  // New method for API compatibility
  static async removeTag(mediaId: number, tagType: string, tagValue: string): Promise<boolean> {
    return removeMediaTagByValue(mediaId, tagType, tagValue)
  }

  static async getTagSuggestions(tagType?: TagType | string): Promise<string[]> {
    return getTagSuggestions(tagType)
  }

  // New method for API compatibility
  static async getExistingTags(tagType?: string): Promise<TagSuggestion[]> {
    return getExistingTags(tagType)
  }

  static async updateThumbnailPaths(id: number, thumbnails: {
    thumbnail_150?: string
    thumbnail_500?: string
    thumbnail_1200?: string
  }): Promise<void> {
    return updateThumbnailPaths(id, thumbnails)
  }

  // Additional method needed by API routes
  static async updateMedia(id: number, updates: Partial<MediaFile>): Promise<MediaFile | null> {
    return updateMediaFile(id, updates)
  }

  /**
   * Delete media file with safety checks
   * Requires admin authentication at API level
   */
  static async deleteMediaFile(id: number): Promise<{
    success: boolean
    deletedFiles: string[]
    errors: string[]
  }> {
    return deleteMediaFile(id)
  }
}